{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "match_info = pd.read_csv(\"data/matches_info.csv\")\n",
    "possessions = pd.read_csv(\"data/possessions.csv\")\n",
    "run_features = pd.read_csv(\"data/run_features.csv\")\n",
    "tracking_data = pd.read_csv(\"data/tracking_data.csv\")\n",
    "player_to_team = pd.read_csv(\"data/player_team.csv\").set_index(\"id\")\n",
    "\n",
    "merged = pd.merge(possessions,run_features,on=[\"match_id\",\"possession_index\"],how=\"outer\",suffixes=(\"_possession\",\"_run\"))\n",
    "\n",
    "merged[\"possession_lead_to_shot\"] = (merged[\"possession_lead_to_shot\"] | merged[\"lead_to_shot\"])# Need to update wheter runs and possessions lead to shots on values that conflict\n",
    "merged[\"possession_lead_to_goal\"] = (merged[\"possession_lead_to_goal\"] | merged[\"lead_to_goal\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f310a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_types_to_predict = ['run_ahead_of_the_ball','cross_receiver','behind']\n",
    "run_to_predict = merged[merged.event_subtype.isin(run_types_to_predict)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3275b46",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def build_graph_from_frame(\n",
    "    frame_df,\n",
    "    runner_player_id,\n",
    "    player_to_team,\n",
    "    R=15.0\n",
    "):\n",
    "    \"\"\"\n",
    "    frame_df: rows = players at ONE frame_id\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1. Sort & extract players\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    frame_df = frame_df.sort_values(\"player\").reset_index(drop=True)\n",
    "\n",
    "    player_ids = frame_df[\"player\"].values\n",
    "    Np = len(player_ids)\n",
    "\n",
    "    # ---------------- Player node features ----------------\n",
    "\n",
    "    player_feats = torch.tensor(\n",
    "        frame_df[[\n",
    "            \"x\", \"y\",\n",
    "            \"dx_smooth\", \"dy_smooth\",\n",
    "            \"speed\",\n",
    "            \"acceleration\"\n",
    "        ]].values,\n",
    "        dtype=torch.float\n",
    "    )\n",
    "\n",
    "    team_ids = torch.tensor(\n",
    "        player_to_team.loc[player_ids, \"team_id\"].values,\n",
    "        dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # runner flag for players\n",
    "    is_runner_player = torch.tensor(\n",
    "        (player_ids == runner_player_id).astype(float),\n",
    "        dtype=torch.float\n",
    "    ).unsqueeze(1)\n",
    "\n",
    "    # append 0 for ball\n",
    "    is_runner = torch.cat(\n",
    "        [is_runner_player, torch.zeros(1, 1)],\n",
    "        dim=0\n",
    "    )\n",
    "\n",
    "    is_ball = torch.zeros(Np + 1, dtype=torch.bool)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2. Ball node\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    ball_feats = torch.tensor(\n",
    "        [[\n",
    "            frame_df[\"ball_x\"].iloc[0],\n",
    "            frame_df[\"ball_y\"].iloc[0],\n",
    "            frame_df[\"ball_dx_smooth\"].iloc[0],\n",
    "            frame_df[\"ball_dy_smooth\"].iloc[0],\n",
    "            frame_df[\"ball_speed\"].iloc[0],\n",
    "            frame_df[\"ball_acceleration\"].iloc[0],\n",
    "        ]],\n",
    "        dtype=torch.float\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3. Combine nodes\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    x = torch.cat([\n",
    "        player_feats,\n",
    "        ball_feats\n",
    "    ], dim=0)\n",
    "\n",
    "    # add indicator features\n",
    "    is_ball[-1] = True\n",
    "    is_ball_feat = is_ball.float().unsqueeze(1)\n",
    "\n",
    "    team_ids = torch.cat([\n",
    "        team_ids,\n",
    "        torch.tensor([-1])\n",
    "    ])\n",
    "\n",
    "    x = torch.cat([\n",
    "        x,\n",
    "        is_runner,\n",
    "        is_ball_feat\n",
    "    ], dim=1)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4. Build edges\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    pos = x[:, :2]\n",
    "    vel = x[:, 2:4]\n",
    "    N = pos.size(0)\n",
    "\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            dist = torch.norm(pos[i] - pos[j])\n",
    "\n",
    "            if (dist < R) or is_ball[i] or is_ball[j]:\n",
    "\n",
    "                same_team = int(\n",
    "                    (team_ids[i] == team_ids[j]) and\n",
    "                    (team_ids[i] != -1)\n",
    "                )\n",
    "\n",
    "                ball_edge = int(is_ball[i] or is_ball[j])\n",
    "\n",
    "                # relative velocity projected onto edge\n",
    "                rel_v = vel[j] - vel[i]\n",
    "                direction = (pos[j] - pos[i]) / (dist + 1e-6)\n",
    "                rel_speed = torch.dot(rel_v, direction)\n",
    "\n",
    "                edge_index.append([i, j])\n",
    "                edge_attr.append([\n",
    "                    dist.item(),\n",
    "                    same_team,\n",
    "                    ball_edge,\n",
    "                    rel_speed.item()\n",
    "                ])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).T\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 5. Runner index\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    runner_idx = int(\n",
    "        torch.where(\n",
    "            torch.tensor(player_ids) == runner_player_id\n",
    "        )[0].item()\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 6. PyG Data object\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    return Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        runner_idx=torch.tensor(runner_idx, dtype=torch.long),\n",
    "        team_ids=team_ids,\n",
    "        is_ball=is_ball\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zcoch\\AppData\\Local\\Temp\\ipykernel_2372\\1346443168.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  run_tracking[\"timestamp\"] = pd.to_timedelta(run_tracking[\"timestamp\"]).dt.total_seconds()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[23, 8], edge_index=[2, 130], edge_attr=[130, 4], runner_idx=1, team_ids=[23], is_ball=[23])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_NUM = 0\n",
    "RUN_FRAME = 2\n",
    "run = run_to_predict.iloc[RUN_NUM]\n",
    "match_id = run[\"match_id\"]\n",
    "run_id = run[\"id\"]\n",
    "player = run[\"player_id\"]\n",
    "\n",
    "run_tracking = tracking_data[(tracking_data.run_id == run_id) & (tracking_data.match_id == match_id)]\n",
    "run_tracking[\"timestamp\"] = pd.to_timedelta(run_tracking[\"timestamp\"]).dt.total_seconds()\n",
    "frame_num = run_tracking[\"frame_id\"].sort_values().iloc[0] + RUN_FRAME\n",
    "frame_df = run_tracking[run_tracking[\"frame_id\"]==frame_num]\n",
    "\n",
    "\n",
    "build_graph_from_frame(frame_df=frame_df,runner_player_id=player,player_to_team=player_to_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fb47c",
   "metadata": {},
   "source": [
    "# Temporal Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9793d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "class TemporalRunnerDataset(Dataset):\n",
    "    def __init__(self, tracking_df, run_features, player_to_team, samples, T=10, horizon=1, R=15.0):\n",
    "        self.df = tracking_df\n",
    "        self.run_features = run_features\n",
    "        self.player_to_team = player_to_team\n",
    "        self.samples = samples\n",
    "        self.T = T\n",
    "        self.horizon = horizon\n",
    "        self.R = R\n",
    "\n",
    "        # group for fast lookup\n",
    "        self.df = self.df.sort_values([\"match_id\", \"frame_id\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        match_id,run_id, frame_t, runner_id = self.samples[idx]\n",
    "\n",
    "        graphs = []\n",
    "\n",
    "        # -------- temporal graphs --------\n",
    "        for t in range(frame_t - self.T + 1, frame_t + 1):\n",
    "\n",
    "            frame_df = self.df[\n",
    "                (self.df[\"match_id\"] == match_id) & \n",
    "                (self.df[\"run_id\"]==run_id) &\n",
    "                (self.df[\"frame_id\"] == t)\n",
    "            ]\n",
    "\n",
    "            g = build_graph_from_frame(\n",
    "                frame_df=frame_df,\n",
    "                runner_player_id=runner_id,\n",
    "                player_to_team=self.player_to_team,\n",
    "                R=self.R\n",
    "            )\n",
    "\n",
    "            graphs.append(g)\n",
    "            \n",
    "        graphs_batch = Batch.from_data_list(graphs)\n",
    "\n",
    "        # -------- target: future runner velocity --------\n",
    "        future = self.df[\n",
    "            (self.df[\"match_id\"] == match_id) & \n",
    "            (self.df[\"run_id\"]==run_id) &\n",
    "            (self.df[\"frame_id\"] == frame_t + self.horizon) &\n",
    "            (self.df[\"player\"] == runner_id)\n",
    "        ]\n",
    "        \n",
    "        target = torch.tensor(\n",
    "            future[[\"dx_smooth\", \"dy_smooth\"]].values.squeeze(),\n",
    "            dtype=torch.float\n",
    "        )\n",
    "        \n",
    "        lead_to_shot_val = self.run_features.loc[self.run_features['id'] == run_id, 'possession_lead_to_shot'].values\n",
    "        if len(lead_to_shot_val) == 0:\n",
    "            shot_label = torch.tensor(0.0)  # or handle missing\n",
    "        else:\n",
    "            shot_label = torch.tensor(float(lead_to_shot_val[0]))\n",
    "\n",
    "        return graphs_batch, target, shot_label\n",
    "\n",
    "def build_samples_from_runs(run_features, T, horizon):\n",
    "    samples = []\n",
    "\n",
    "    for _, run in run_features.iterrows():\n",
    "        match_id = run[\"match_id\"]\n",
    "        run_id = run[\"event_id\"]\n",
    "        runner_id = run[\"player_id\"]\n",
    "\n",
    "        frame_start = int(run[\"frame_start_run\"])\n",
    "        frame_end = int(run[\"frame_end_run\"])\n",
    "\n",
    "        # earliest frame we can use (need T past frames)\n",
    "        t_min = frame_start + T - 1\n",
    "        t_max = frame_end - horizon\n",
    "\n",
    "        if t_min > t_max:\n",
    "            continue  # run too short\n",
    "\n",
    "        for t in range(t_min, t_max + 1):\n",
    "            samples.append(\n",
    "                (match_id,run_id, t, runner_id)\n",
    "            )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "47812f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "horizon = 1\n",
    "\n",
    "samples = build_samples_from_runs(run_to_predict, T, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5e1633f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TemporalRunnerDataset at 0x2bf12a11400>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TemporalRunnerDataset(\n",
    "    tracking_df=tracking_data,\n",
    "    run_features=run_to_predict,\n",
    "    player_to_team=player_to_team,\n",
    "    samples=samples,\n",
    "    T=10,\n",
    "    horizon=1,\n",
    "    R=15.0\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869039f8",
   "metadata": {},
   "source": [
    "# Temporal GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7b1f89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv  # or other GNN layer\n",
    "\n",
    "class TemporalRunnerGNN(nn.Module):\n",
    "    def __init__(self, node_feat_dim, gnn_hidden_dim, rnn_hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gnn1 = GCNConv(node_feat_dim, gnn_hidden_dim)\n",
    "        self.gnn2 = GCNConv(gnn_hidden_dim, gnn_hidden_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=gnn_hidden_dim,\n",
    "            hidden_size=rnn_hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.pos_head = nn.Linear(rnn_hidden_dim, 2)\n",
    "        self.shot_head = nn.Linear(rnn_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, graphs_batch):\n",
    "        \"\"\"\n",
    "        graphs_batch: PyG Batch containing T graphs (time steps)\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        graphs_batch = graphs_batch.to(device)\n",
    "\n",
    "        x, edge_index = graphs_batch.x, graphs_batch.edge_index\n",
    "\n",
    "        # ---- GNN ----\n",
    "        x = F.relu(self.gnn1(x, edge_index))\n",
    "        x = F.relu(self.gnn2(x, edge_index))\n",
    "\n",
    "        # ---- Extract runner embeddings per timestep ----\n",
    "        batch_vec = graphs_batch.batch          # [num_nodes]\n",
    "        runner_idx = graphs_batch.runner_idx    # [T]\n",
    "\n",
    "        T = runner_idx.size(0)\n",
    "        runner_embeds = []\n",
    "\n",
    "        for t in range(T):\n",
    "            node_mask = (batch_vec == t)\n",
    "            node_indices = node_mask.nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "            global_runner_idx = node_indices[runner_idx[t]]\n",
    "            runner_embeds.append(x[global_runner_idx])\n",
    "\n",
    "        # [T, H] â†’ [1, T, H]\n",
    "        runner_embeds = torch.stack(runner_embeds).unsqueeze(0)\n",
    "\n",
    "        # ---- Temporal model ----\n",
    "        out, _ = self.rnn(runner_embeds)\n",
    "        last_out = out[:, -1, :]  # [1, H]\n",
    "\n",
    "        pred_pos = self.pos_head(last_out).squeeze(0)        # [2]\n",
    "        pred_shot = self.shot_head(last_out).squeeze(0)      # [1]\n",
    "\n",
    "        return pred_pos, pred_shot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f21682",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/36232 [00:04<40:22:27,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/36232 [00:08<41:32:44,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/36232 [00:12<41:22:41,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/36232 [00:16<41:22:17,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/36232 [00:17<43:56:45,  4.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     20\u001b[39m     total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshot_label\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot_label\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mTemporalRunnerDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# -------- temporal graphs --------\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frame_t - \u001b[38;5;28mself\u001b[39m.T + \u001b[32m1\u001b[39m, frame_t + \u001b[32m1\u001b[39m):\n\u001b[32m     27\u001b[39m     frame_df = \u001b[38;5;28mself\u001b[39m.df[\n\u001b[32m     28\u001b[39m         (\u001b[38;5;28mself\u001b[39m.df[\u001b[33m\"\u001b[39m\u001b[33mmatch_id\u001b[39m\u001b[33m\"\u001b[39m] == match_id) & \n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m==\u001b[49m\u001b[43mrun_id\u001b[49m) &\n\u001b[32m     30\u001b[39m         (\u001b[38;5;28mself\u001b[39m.df[\u001b[33m\"\u001b[39m\u001b[33mframe_id\u001b[39m\u001b[33m\"\u001b[39m] == t)\n\u001b[32m     31\u001b[39m     ]\n\u001b[32m     33\u001b[39m     g = build_graph_from_frame(\n\u001b[32m     34\u001b[39m         frame_df=frame_df,\n\u001b[32m     35\u001b[39m         runner_player_id=runner_id,\n\u001b[32m     36\u001b[39m         player_to_team=\u001b[38;5;28mself\u001b[39m.player_to_team,\n\u001b[32m     37\u001b[39m         R=\u001b[38;5;28mself\u001b[39m.R\n\u001b[32m     38\u001b[39m     )\n\u001b[32m     40\u001b[39m     graphs.append(g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\series.py:6130\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    129\u001b[39m     result = libops.scalar_compare(x.ravel(), y, op)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparams\n",
    "alpha = 1.0  # weight for shot loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume model, dataset are already created\n",
    "model = TemporalRunnerGNN(node_feat_dim=8, gnn_hidden_dim=64, rnn_hidden_dim=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=1, shuffle=True)  # batch_size=1 for now\n",
    "dataloader = GeoDataLoader(dataset, batch_size=1, shuffle=True)\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for graphs, target, shot_label in tqdm(dataloader):\n",
    "        target = target.to(device).squeeze(0)\n",
    "        shot_label = shot_label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_pos, pred_shot = model(graphs)\n",
    "        \n",
    "        assert pred_pos.shape == target.shape\n",
    "        assert pred_shot.shape == shot_label.shape\n",
    "        \n",
    "        weight = shot_label + 0.1 \n",
    "        \n",
    "        loss_pos = weight * F.mse_loss(pred_pos, target)\n",
    "        loss_shot = F.binary_cross_entropy_with_logits(pred_shot.view(1),shot_label.view(1))\n",
    "        loss = loss_pos + alpha * loss_shot\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17844a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
